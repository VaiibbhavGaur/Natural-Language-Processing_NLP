{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1b. Text Classification Exercise - Movie Reviews.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JP6ss_CojMw4"},"source":["# Text Classification Exercise: Movie Reviews"]},{"cell_type":"markdown","metadata":{"id":"xONn7mqYjMw6"},"source":["## Introduction\n","\n","This exercise uses the data from Kaggle's [IMDB Movie reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) competition.\n","\n","**Description of the data:**\n","\n","- **`labeledTrainData.tsv.zip`** contains the dataset.\n","- Each observation in this dataset is a review of a movie by a user.\n","- The **sentiment** column is the sentiment of the review (1 -> positive and 0 -> negative).\n","- The **review** column is the text of the review."]},{"cell_type":"code","metadata":{"id":"evvJtcnyaeO_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610848238225,"user_tz":-330,"elapsed":21997,"user":{"displayName":"Vaibhav Gaur","photoUrl":"https://lh5.googleusercontent.com/-twHoaFSOjdQ/AAAAAAAAAAI/AAAAAAAABq4/ZKN-1Hal56g/s64/photo.jpg","userId":"01960529911757102386"}},"outputId":"7f41a35f-168d-4b79-f8ed-ededfc5dcc68"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9uMFsTz0lZZ","executionInfo":{"status":"ok","timestamp":1610848243452,"user_tz":-330,"elapsed":2798,"user":{"displayName":"Vaibhav Gaur","photoUrl":"https://lh5.googleusercontent.com/-twHoaFSOjdQ/AAAAAAAAAAI/AAAAAAAABq4/ZKN-1Hal56g/s64/photo.jpg","userId":"01960529911757102386"}},"outputId":"e801338b-9e6b-4883-a943-445e397b3046"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o84tU4KBruJK","executionInfo":{"status":"ok","timestamp":1610848245575,"user_tz":-330,"elapsed":2165,"user":{"displayName":"Vaibhav Gaur","photoUrl":"https://lh5.googleusercontent.com/-twHoaFSOjdQ/AAAAAAAAAAI/AAAAAAAABq4/ZKN-1Hal56g/s64/photo.jpg","userId":"01960529911757102386"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xlJpnzDwjMw8"},"source":["# **Goal:** Predict the sentiment of the review using the review text."]},{"cell_type":"markdown","metadata":{"id":"suvnxBMljMw9"},"source":["## Task 1\n","\n","Read **`labeledTrainData.tsv.zip`** into a pandas DataFrame and examine it. Please note that pandas can directly read tsv/csv files inside a zip file."]},{"cell_type":"code","metadata":{"id":"6EK43j_iRYYz","executionInfo":{"status":"ok","timestamp":1610848300870,"user_tz":-330,"elapsed":3117,"user":{"displayName":"Vaibhav Gaur","photoUrl":"https://lh5.googleusercontent.com/-twHoaFSOjdQ/AAAAAAAAAAI/AAAAAAAABq4/ZKN-1Hal56g/s64/photo.jpg","userId":"01960529911757102386"}}},"source":["df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/labeledTrainData.tsv.zip',header=0, delimiter=\"\\t\", quoting=3)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OXDPlZp3jMw_"},"source":["## Task 2\n","\n","Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the **review** as the feature and the **sentiment** as the response.\n","\n","- **Hint:** Keep in mind that X should be a pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."]},{"cell_type":"code","metadata":{"id":"RhwJR8OTTl8m","executionInfo":{"status":"ok","timestamp":1610848342845,"user_tz":-330,"elapsed":2256,"user":{"displayName":"Vaibhav Gaur","photoUrl":"https://lh5.googleusercontent.com/-twHoaFSOjdQ/AAAAAAAAAAI/AAAAAAAABq4/ZKN-1Hal56g/s64/photo.jpg","userId":"01960529911757102386"}}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df['review'],\n","    df['sentiment'],\n","    test_size=0.2, \n","    random_state=42\n",")"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LAfxXoeZjMxA"},"source":["## Task 3\n","\n","Use CountVectorizer to create **document-term matrices** from X_train and X_test."]},{"cell_type":"code","metadata":{"id":"yY5w6wgqDawH","executionInfo":{"status":"ok","timestamp":1610848517239,"user_tz":-330,"elapsed":1559,"user":{"displayName":"Vaibhav Gaur","photoUrl":"https://lh5.googleusercontent.com/-twHoaFSOjdQ/AAAAAAAAAAI/AAAAAAAABq4/ZKN-1Hal56g/s64/photo.jpg","userId":"01960529911757102386"}}},"source":["from sklearn.feature_extraction.text import CountVectorizer\r\n","cvect = CountVectorizer()"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kG7kVIqojMxB"},"source":["## Task 4\n","\n","Use multinomial Naive Bayes to **predict the sentiment** for the reviews in the testing set, and then **calculate the accuracy** and **print the confusion matrix**."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"dTTiyUW-EHeJ","executionInfo":{"status":"error","timestamp":1610848894508,"user_tz":-330,"elapsed":1810,"user":{"displayName":"Vaibhav Gaur","photoUrl":"https://lh5.googleusercontent.com/-twHoaFSOjdQ/AAAAAAAAAAI/AAAAAAAABq4/ZKN-1Hal56g/s64/photo.jpg","userId":"01960529911757102386"}},"outputId":"aa9e9e39-2fdb-47a1-e545-fa4070bf8e10"},"source":["from sklearn.naive_bayes import MultinomialNB\r\n","mlb = MultinomialNB()\r\n","\r\n","# fit the model with data (occurs in-place)\r\n","mlb.fit(X_train, y_train)"],"execution_count":12,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-12-7e61d3eb5bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# fit the model with data (occurs in-place)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \"\"\"\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'M8[ns]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/arrays/numpy_.pyc\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"This movie is just plain dumb.<br /><br />From the casting of Ralph Meeker as Mike Hammer to the fatuous climax, the film is an exercise in wooden predictability.<br /><br />Mike Hammer is one of det"]}]},{"cell_type":"markdown","metadata":{"id":"Y-9ERAlfjMxD"},"source":["## Task 5\n","\n","Calculate the **null accuracy**, which is the classification accuracy that could be achieved by always predicting the most frequent class."]},{"cell_type":"markdown","metadata":{"id":"gvduejPajMxG"},"source":["## Task 6\n","\n","Use different **tuning parameters** e.g max_df, min_df, max_features etc to build models and check test accuracy.\n","\n","Hint:\n","\n","- You can write a function which accepts a vectorizer as a parameter and..\n","- Create DTMs for Training and Test data\n","- Trains a model (SVM)\n","- Calculate the testing accuracy and prints the same\n","\n","Call the above function with Vectorizers object created using different tuning parameters. Use TF-IDF vectorizer for this task."]},{"cell_type":"code","metadata":{"id":"1yhWQzYVRouO"},"source":["def model_build(vect):\n","\n","    #Create DTM for Training and  Test\n","    \n","    #Build an SVM Classifier\n","\n","    #Display Test Accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zo9CIv_BR6OW"},"source":["vect = TfidfVectorizer(min_df=2)\n","model_build(vect)"],"execution_count":null,"outputs":[]}]}