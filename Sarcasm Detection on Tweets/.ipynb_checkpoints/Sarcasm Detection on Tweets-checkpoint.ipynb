{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pp68FAQf9aMN"
   },
   "source": [
    "# Sarcasm Detection On Twitter Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Rubrics: \n",
    "\n",
    "1. Read and explore the data [ Score: 2 Points ]\n",
    "2. Retain relevant columns [ Score: 2 Points ]\n",
    "3. Get length of each sentence [ Score: 2 Points ]\n",
    "4. Define parameters [ Score: 2 Points ]\n",
    "5. Get indices for words [ Score: 5 Points ]\n",
    "6. Create features and labels [ Score: 5 Points ]\n",
    "7. Get vocabulary size [ Score: 2 Points ]\n",
    "8. Create a weight matrix using GloVe embeddings [ Score: 2 Points ]\n",
    "9. Define and compile a Bidirectional LSTM model. [ Score: 6 Points ]\n",
    "\t     Hint: Be analytical and experimental here in trying new approaches to design the best model.\n",
    "10. Fit the model and check the validation accuracy. [ Score: 2 Points ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-demographic",
   "metadata": {},
   "source": [
    "## 1. Read and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "surrounded-credit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "spatial-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26709, 3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dominican-tyler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14985\n",
       "1    11724\n",
       "Name: is_sarcastic, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_sarcastic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "active-grant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_link', 'headline', 'is_sarcastic'], dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-mechanism",
   "metadata": {},
   "source": [
    "## 2. Retain relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "entitled-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['headline','is_sarcastic']]  # Remove column article link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fancy-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['headline', 'is_sarcastic'], dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fatty-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-factor",
   "metadata": {},
   "source": [
    "## 3. Get length of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "played-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['headline'].astype(str).map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "vietnamese-lottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>american politics in moral free-fall</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>america's best 20 hikes</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>reparations and obama</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>israeli ban targeting boycott supporters raise...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>gourmet gifts for the foodie 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26709 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic  length\n",
       "0      former versace store clerk sues over secret 'b...             0      78\n",
       "1      the 'roseanne' revival catches up to our thorn...             0      84\n",
       "2      mom starting to fear son's web series closest ...             1      79\n",
       "3      boehner just wants wife to listen, not come up...             1      84\n",
       "4      j.k. rowling wishes snape happy birthday in th...             0      64\n",
       "...                                                  ...           ...     ...\n",
       "26704               american politics in moral free-fall             0      36\n",
       "26705                            america's best 20 hikes             0      23\n",
       "26706                              reparations and obama             0      21\n",
       "26707  israeli ban targeting boycott supporters raise...             0      60\n",
       "26708                  gourmet gifts for the foodie 2014             0      33\n",
       "\n",
       "[26709 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-brunswick",
   "metadata": {},
   "source": [
    "## 4. Create Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "confident-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "united-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['headline'], df['is_sarcastic'], \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "convenient-decimal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21367,), (21367,))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "recent-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-insider",
   "metadata": {},
   "source": [
    "## 5. Get Vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "egyptian-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_vocab_size = 10000 #Vocablury size\n",
    "t = tf.keras.preprocessing.text.Tokenizer(num_words=desired_vocab_size,oov_token='OOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "conventional-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit tokenizer with actual training data\n",
    "t.fit_on_texts(X_train.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-cologne",
   "metadata": {},
   "source": [
    "## 6. Get inices of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "breathing-tournament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OOV': 1,\n",
       " 'to': 2,\n",
       " 'of': 3,\n",
       " 'the': 4,\n",
       " 'in': 5,\n",
       " 'for': 6,\n",
       " 'a': 7,\n",
       " 'on': 8,\n",
       " 'and': 9,\n",
       " 'with': 10,\n",
       " 'is': 11,\n",
       " 'new': 12,\n",
       " 'trump': 13,\n",
       " 'man': 14,\n",
       " 'from': 15,\n",
       " 'at': 16,\n",
       " 'about': 17,\n",
       " 'you': 18,\n",
       " 'this': 19,\n",
       " 'by': 20,\n",
       " 'after': 21,\n",
       " 'up': 22,\n",
       " 'out': 23,\n",
       " 'be': 24,\n",
       " 'how': 25,\n",
       " 'it': 26,\n",
       " 'as': 27,\n",
       " 'that': 28,\n",
       " 'not': 29,\n",
       " 'your': 30,\n",
       " 'his': 31,\n",
       " 'are': 32,\n",
       " 'what': 33,\n",
       " 'he': 34,\n",
       " 'all': 35,\n",
       " 'has': 36,\n",
       " 'just': 37,\n",
       " 'who': 38,\n",
       " 'more': 39,\n",
       " 'will': 40,\n",
       " 'one': 41,\n",
       " 'into': 42,\n",
       " 'report': 43,\n",
       " 'area': 44,\n",
       " 'have': 45,\n",
       " 'why': 46,\n",
       " 'donald': 47,\n",
       " 'year': 48,\n",
       " 'over': 49,\n",
       " 'u': 50,\n",
       " 'can': 51,\n",
       " 's': 52,\n",
       " 'day': 53,\n",
       " 'says': 54,\n",
       " 'woman': 55,\n",
       " 'first': 56,\n",
       " 'time': 57,\n",
       " \"trump's\": 58,\n",
       " 'her': 59,\n",
       " 'off': 60,\n",
       " 'like': 61,\n",
       " 'old': 62,\n",
       " 'no': 63,\n",
       " 'an': 64,\n",
       " 'get': 65,\n",
       " 'obama': 66,\n",
       " 'now': 67,\n",
       " 'people': 68,\n",
       " 'life': 69,\n",
       " 'make': 70,\n",
       " 'was': 71,\n",
       " 'than': 72,\n",
       " 'still': 73,\n",
       " \"'\": 74,\n",
       " 'house': 75,\n",
       " 'if': 76,\n",
       " 'back': 77,\n",
       " 'white': 78,\n",
       " 'i': 79,\n",
       " 'women': 80,\n",
       " 'clinton': 81,\n",
       " 'my': 82,\n",
       " 'when': 83,\n",
       " 'down': 84,\n",
       " '5': 85,\n",
       " 'world': 86,\n",
       " 'we': 87,\n",
       " 'could': 88,\n",
       " 'before': 89,\n",
       " 'americans': 90,\n",
       " 'way': 91,\n",
       " 'most': 92,\n",
       " 'study': 93,\n",
       " 'do': 94,\n",
       " 'their': 95,\n",
       " 'family': 96,\n",
       " 'black': 97,\n",
       " \"it's\": 98,\n",
       " 'school': 99,\n",
       " 'would': 100,\n",
       " 'only': 101,\n",
       " 'gop': 102,\n",
       " 'they': 103,\n",
       " 'best': 104,\n",
       " 'should': 105,\n",
       " 'really': 106,\n",
       " 'being': 107,\n",
       " '3': 108,\n",
       " 'him': 109,\n",
       " 'years': 110,\n",
       " 'police': 111,\n",
       " 'so': 112,\n",
       " 'watch': 113,\n",
       " \"can't\": 114,\n",
       " 'last': 115,\n",
       " 'bill': 116,\n",
       " 'going': 117,\n",
       " 'during': 118,\n",
       " 'but': 119,\n",
       " 'death': 120,\n",
       " 'home': 121,\n",
       " 'american': 122,\n",
       " 'know': 123,\n",
       " 'nation': 124,\n",
       " 'health': 125,\n",
       " 'finds': 126,\n",
       " 'show': 127,\n",
       " 'state': 128,\n",
       " 'good': 129,\n",
       " '10': 130,\n",
       " 'video': 131,\n",
       " 'or': 132,\n",
       " 'president': 133,\n",
       " 'say': 134,\n",
       " 'mom': 135,\n",
       " \"'the\": 136,\n",
       " 'right': 137,\n",
       " 'may': 138,\n",
       " 'things': 139,\n",
       " 'every': 140,\n",
       " 'against': 141,\n",
       " 'she': 142,\n",
       " 'too': 143,\n",
       " 'hillary': 144,\n",
       " 'getting': 145,\n",
       " '000': 146,\n",
       " 'gets': 147,\n",
       " 'campaign': 148,\n",
       " 'kids': 149,\n",
       " '2': 150,\n",
       " 'party': 151,\n",
       " 'love': 152,\n",
       " 'parents': 153,\n",
       " 'need': 154,\n",
       " 'big': 155,\n",
       " 'these': 156,\n",
       " 'other': 157,\n",
       " 'court': 158,\n",
       " 'makes': 159,\n",
       " 'some': 160,\n",
       " 'change': 161,\n",
       " 'our': 162,\n",
       " 'self': 163,\n",
       " 'high': 164,\n",
       " 'america': 165,\n",
       " 'john': 166,\n",
       " 'little': 167,\n",
       " 'own': 168,\n",
       " \"here's\": 169,\n",
       " 'see': 170,\n",
       " 'dead': 171,\n",
       " 'take': 172,\n",
       " 'calls': 173,\n",
       " 'takes': 174,\n",
       " 'while': 175,\n",
       " 'child': 176,\n",
       " \"nation's\": 177,\n",
       " 'go': 178,\n",
       " 'work': 179,\n",
       " 'want': 180,\n",
       " 'where': 181,\n",
       " 'through': 182,\n",
       " 'its': 183,\n",
       " 'real': 184,\n",
       " 'even': 185,\n",
       " '4': 186,\n",
       " 'gay': 187,\n",
       " 'college': 188,\n",
       " 'stop': 189,\n",
       " 'local': 190,\n",
       " '7': 191,\n",
       " 'plan': 192,\n",
       " 'election': 193,\n",
       " 'never': 194,\n",
       " \"doesn't\": 195,\n",
       " 'news': 196,\n",
       " 'next': 197,\n",
       " \"don't\": 198,\n",
       " 'look': 199,\n",
       " \"he's\": 200,\n",
       " 'dad': 201,\n",
       " '6': 202,\n",
       " 'war': 203,\n",
       " 'bush': 204,\n",
       " 'made': 205,\n",
       " 'guy': 206,\n",
       " 'another': 207,\n",
       " 'two': 208,\n",
       " 'again': 209,\n",
       " 'dog': 210,\n",
       " 'office': 211,\n",
       " 'help': 212,\n",
       " 'ever': 213,\n",
       " 'care': 214,\n",
       " 'north': 215,\n",
       " 'much': 216,\n",
       " 'wants': 217,\n",
       " 'baby': 218,\n",
       " 'debate': 219,\n",
       " 'week': 220,\n",
       " 'thing': 221,\n",
       " 'gun': 222,\n",
       " 'sex': 223,\n",
       " '1': 224,\n",
       " 'actually': 225,\n",
       " 'got': 226,\n",
       " 'been': 227,\n",
       " 'long': 228,\n",
       " 'congress': 229,\n",
       " 'finally': 230,\n",
       " 'season': 231,\n",
       " 'us': 232,\n",
       " 'million': 233,\n",
       " 'them': 234,\n",
       " 'around': 235,\n",
       " 'announces': 236,\n",
       " 'national': 237,\n",
       " 'job': 238,\n",
       " 'night': 239,\n",
       " 'away': 240,\n",
       " 'live': 241,\n",
       " 'food': 242,\n",
       " 'teen': 243,\n",
       " 'anti': 244,\n",
       " '20': 245,\n",
       " '9': 246,\n",
       " 'money': 247,\n",
       " 'top': 248,\n",
       " \"won't\": 249,\n",
       " 'ways': 250,\n",
       " 'sexual': 251,\n",
       " 'facebook': 252,\n",
       " 'media': 253,\n",
       " 'better': 254,\n",
       " \"man's\": 255,\n",
       " 'under': 256,\n",
       " 'end': 257,\n",
       " 'face': 258,\n",
       " '8': 259,\n",
       " 'bad': 260,\n",
       " 'climate': 261,\n",
       " 'paul': 262,\n",
       " 'had': 263,\n",
       " 'couple': 264,\n",
       " 'without': 265,\n",
       " 'supreme': 266,\n",
       " 'senate': 267,\n",
       " 'give': 268,\n",
       " 'trying': 269,\n",
       " 'reveals': 270,\n",
       " 'any': 271,\n",
       " 'shooting': 272,\n",
       " 'law': 273,\n",
       " 'star': 274,\n",
       " 'fight': 275,\n",
       " 'enough': 276,\n",
       " 'children': 277,\n",
       " 'story': 278,\n",
       " 'history': 279,\n",
       " 'government': 280,\n",
       " 'shows': 281,\n",
       " 'wedding': 282,\n",
       " 'making': 283,\n",
       " 'men': 284,\n",
       " 'attack': 285,\n",
       " 'game': 286,\n",
       " 'me': 287,\n",
       " 'fire': 288,\n",
       " '11': 289,\n",
       " 'there': 290,\n",
       " 'free': 291,\n",
       " 'everyone': 292,\n",
       " 'book': 293,\n",
       " 'movie': 294,\n",
       " 'photos': 295,\n",
       " 'students': 296,\n",
       " 'god': 297,\n",
       " 'friends': 298,\n",
       " 'does': 299,\n",
       " 'found': 300,\n",
       " 'introduces': 301,\n",
       " 'york': 302,\n",
       " 'son': 303,\n",
       " 'girl': 304,\n",
       " 'deal': 305,\n",
       " 'former': 306,\n",
       " 'part': 307,\n",
       " 'body': 308,\n",
       " 'tv': 309,\n",
       " 'film': 310,\n",
       " 'middle': 311,\n",
       " 'business': 312,\n",
       " \"world's\": 313,\n",
       " 'great': 314,\n",
       " 'pope': 315,\n",
       " 'tell': 316,\n",
       " 'second': 317,\n",
       " 'car': 318,\n",
       " 'republican': 319,\n",
       " 'entire': 320,\n",
       " 'power': 321,\n",
       " 'find': 322,\n",
       " 'use': 323,\n",
       " 'talk': 324,\n",
       " 'city': 325,\n",
       " 'same': 326,\n",
       " 'must': 327,\n",
       " 'keep': 328,\n",
       " 'come': 329,\n",
       " 'thinks': 330,\n",
       " 'single': 331,\n",
       " 'call': 332,\n",
       " 'presidential': 333,\n",
       " 'name': 334,\n",
       " 'speech': 335,\n",
       " '12': 336,\n",
       " 'republicans': 337,\n",
       " 'behind': 338,\n",
       " 'group': 339,\n",
       " 'democrats': 340,\n",
       " 'support': 341,\n",
       " 'run': 342,\n",
       " 'looking': 343,\n",
       " 'morning': 344,\n",
       " 'email': 345,\n",
       " 'think': 346,\n",
       " 'company': 347,\n",
       " 'asks': 348,\n",
       " 'might': 349,\n",
       " 'case': 350,\n",
       " 'coming': 351,\n",
       " 'tax': 352,\n",
       " 'control': 353,\n",
       " 'having': 354,\n",
       " 'friend': 355,\n",
       " 'pretty': 356,\n",
       " 'full': 357,\n",
       " 'once': 358,\n",
       " 'future': 359,\n",
       " \"didn't\": 360,\n",
       " 'public': 361,\n",
       " 'used': 362,\n",
       " 'already': 363,\n",
       " 'vote': 364,\n",
       " 'sanders': 365,\n",
       " 'james': 366,\n",
       " 'christmas': 367,\n",
       " 'doing': 368,\n",
       " 'killed': 369,\n",
       " 'line': 370,\n",
       " 'goes': 371,\n",
       " 'between': 372,\n",
       " 'department': 373,\n",
       " 'open': 374,\n",
       " 'releases': 375,\n",
       " 'twitter': 376,\n",
       " 'rights': 377,\n",
       " 'security': 378,\n",
       " 'super': 379,\n",
       " 'ban': 380,\n",
       " 'each': 381,\n",
       " 'student': 382,\n",
       " 'music': 383,\n",
       " 'perfect': 384,\n",
       " '2016': 385,\n",
       " 'ad': 386,\n",
       " 'month': 387,\n",
       " 'wife': 388,\n",
       " 'claims': 389,\n",
       " 'missing': 390,\n",
       " 'room': 391,\n",
       " 'record': 392,\n",
       " 'fans': 393,\n",
       " 'save': 394,\n",
       " 'win': 395,\n",
       " 'female': 396,\n",
       " 'minutes': 397,\n",
       " 'photo': 398,\n",
       " 'marriage': 399,\n",
       " 'teacher': 400,\n",
       " 'plans': 401,\n",
       " 'inside': 402,\n",
       " 'person': 403,\n",
       " 'past': 404,\n",
       " 'start': 405,\n",
       " 'violence': 406,\n",
       " 'three': 407,\n",
       " 'living': 408,\n",
       " 'bernie': 409,\n",
       " 'post': 410,\n",
       " 'team': 411,\n",
       " 'shot': 412,\n",
       " 'forced': 413,\n",
       " 'poll': 414,\n",
       " 'secret': 415,\n",
       " 'boy': 416,\n",
       " 'something': 417,\n",
       " 'very': 418,\n",
       " 'tells': 419,\n",
       " 'water': 420,\n",
       " 'list': 421,\n",
       " 'reports': 422,\n",
       " 'ready': 423,\n",
       " 'race': 424,\n",
       " 'sure': 425,\n",
       " 'put': 426,\n",
       " 'country': 427,\n",
       " 'human': 428,\n",
       " 'class': 429,\n",
       " 'employee': 430,\n",
       " 'needs': 431,\n",
       " 'mike': 432,\n",
       " '15': 433,\n",
       " 'red': 434,\n",
       " 'texas': 435,\n",
       " 'admits': 436,\n",
       " 'until': 437,\n",
       " 'were': 438,\n",
       " 'art': 439,\n",
       " 'always': 440,\n",
       " 'times': 441,\n",
       " 'dies': 442,\n",
       " 'political': 443,\n",
       " 'biden': 444,\n",
       " 'meet': 445,\n",
       " 'here': 446,\n",
       " 'korea': 447,\n",
       " 'ryan': 448,\n",
       " 'talks': 449,\n",
       " 'summer': 450,\n",
       " 'hot': 451,\n",
       " 'obamacare': 452,\n",
       " 'voters': 453,\n",
       " 'michael': 454,\n",
       " 'states': 455,\n",
       " 'judge': 456,\n",
       " 'let': 457,\n",
       " 'everything': 458,\n",
       " 'unveils': 459,\n",
       " 'head': 460,\n",
       " 'running': 461,\n",
       " 'left': 462,\n",
       " 'age': 463,\n",
       " \"women's\": 464,\n",
       " 'because': 465,\n",
       " 'social': 466,\n",
       " 'young': 467,\n",
       " 'daughter': 468,\n",
       " 'cruz': 469,\n",
       " 'percent': 470,\n",
       " 'scientists': 471,\n",
       " 'many': 472,\n",
       " 'looks': 473,\n",
       " 'russia': 474,\n",
       " 'working': 475,\n",
       " 'thought': 476,\n",
       " 'chief': 477,\n",
       " 'taking': 478,\n",
       " 'comes': 479,\n",
       " 'attacks': 480,\n",
       " 'south': 481,\n",
       " 'heart': 482,\n",
       " 'third': 483,\n",
       " 'eating': 484,\n",
       " 'set': 485,\n",
       " 'thousands': 486,\n",
       " 'tweets': 487,\n",
       " 'fucking': 488,\n",
       " 'days': 489,\n",
       " 'owner': 490,\n",
       " 'meeting': 491,\n",
       " 'warns': 492,\n",
       " 'lives': 493,\n",
       " 'father': 494,\n",
       " 'did': 495,\n",
       " 'hours': 496,\n",
       " 'town': 497,\n",
       " 'probably': 498,\n",
       " 'cancer': 499,\n",
       " 'pay': 500,\n",
       " 'romney': 501,\n",
       " 'secretary': 502,\n",
       " 'idea': 503,\n",
       " '30': 504,\n",
       " 'kim': 505,\n",
       " 'washington': 506,\n",
       " '50': 507,\n",
       " \"what's\": 508,\n",
       " 'tips': 509,\n",
       " \"she's\": 510,\n",
       " 'california': 511,\n",
       " 'sleep': 512,\n",
       " 'street': 513,\n",
       " 'candidate': 514,\n",
       " 'military': 515,\n",
       " 'wall': 516,\n",
       " 'feel': 517,\n",
       " 'yet': 518,\n",
       " 'wrong': 519,\n",
       " 'air': 520,\n",
       " 'kill': 521,\n",
       " 'mother': 522,\n",
       " 'service': 523,\n",
       " 'nuclear': 524,\n",
       " \"you're\": 525,\n",
       " 'ted': 526,\n",
       " 'lost': 527,\n",
       " 'internet': 528,\n",
       " 'fbi': 529,\n",
       " 'phone': 530,\n",
       " 'cat': 531,\n",
       " 'george': 532,\n",
       " 'today': 533,\n",
       " 'leaves': 534,\n",
       " 'restaurant': 535,\n",
       " 'someone': 536,\n",
       " 'education': 537,\n",
       " 'well': 538,\n",
       " 'gives': 539,\n",
       " 'drug': 540,\n",
       " 'crisis': 541,\n",
       " 'guide': 542,\n",
       " 'holiday': 543,\n",
       " 'isis': 544,\n",
       " 'giving': 545,\n",
       " 'justice': 546,\n",
       " 'half': 547,\n",
       " 'place': 548,\n",
       " 'iran': 549,\n",
       " 'immigration': 550,\n",
       " \"'i\": 551,\n",
       " 'king': 552,\n",
       " 'mark': 553,\n",
       " 'hour': 554,\n",
       " 'shit': 555,\n",
       " 'ex': 556,\n",
       " 'democratic': 557,\n",
       " 'few': 558,\n",
       " 'fan': 559,\n",
       " 'march': 560,\n",
       " 'thinking': 561,\n",
       " 'administration': 562,\n",
       " 'ceo': 563,\n",
       " 'girlfriend': 564,\n",
       " 'federal': 565,\n",
       " 'online': 566,\n",
       " 'cover': 567,\n",
       " 'latest': 568,\n",
       " 'stars': 569,\n",
       " 'together': 570,\n",
       " 'using': 571,\n",
       " 'officials': 572,\n",
       " \"i'm\": 573,\n",
       " 'travel': 574,\n",
       " 'al': 575,\n",
       " 'breaking': 576,\n",
       " 'hollywood': 577,\n",
       " 'move': 578,\n",
       " 'prison': 579,\n",
       " 'abortion': 580,\n",
       " 'knows': 581,\n",
       " 'series': 582,\n",
       " 'letter': 583,\n",
       " 'order': 584,\n",
       " 'minute': 585,\n",
       " 'wins': 586,\n",
       " 'read': 587,\n",
       " 'chris': 588,\n",
       " 'talking': 589,\n",
       " 'earth': 590,\n",
       " 'months': 591,\n",
       " '2015': 592,\n",
       " 'personal': 593,\n",
       " 'hair': 594,\n",
       " 'himself': 595,\n",
       " 'those': 596,\n",
       " 'since': 597,\n",
       " 'wearing': 598,\n",
       " 'rules': 599,\n",
       " 'outside': 600,\n",
       " 'hard': 601,\n",
       " 'director': 602,\n",
       " 'interview': 603,\n",
       " 'stephen': 604,\n",
       " 'believe': 605,\n",
       " 'straight': 606,\n",
       " 'bar': 607,\n",
       " 'watching': 608,\n",
       " 'relationship': 609,\n",
       " 'favorite': 610,\n",
       " 'late': 611,\n",
       " 'visit': 612,\n",
       " 'less': 613,\n",
       " 'union': 614,\n",
       " 'rock': 615,\n",
       " \"obama's\": 616,\n",
       " 'excited': 617,\n",
       " 'message': 618,\n",
       " 'lot': 619,\n",
       " 'awards': 620,\n",
       " 'reason': 621,\n",
       " 'issues': 622,\n",
       " 'small': 623,\n",
       " 'florida': 624,\n",
       " \"isn't\": 625,\n",
       " 'called': 626,\n",
       " 'non': 627,\n",
       " 'questions': 628,\n",
       " 't': 629,\n",
       " 'happy': 630,\n",
       " 'response': 631,\n",
       " 'front': 632,\n",
       " 'dream': 633,\n",
       " 'community': 634,\n",
       " 'die': 635,\n",
       " 'united': 636,\n",
       " 'beautiful': 637,\n",
       " 'leaders': 638,\n",
       " 'word': 639,\n",
       " 'david': 640,\n",
       " 'investigation': 641,\n",
       " 'birthday': 642,\n",
       " 'career': 643,\n",
       " 'totally': 644,\n",
       " 'protest': 645,\n",
       " 'assault': 646,\n",
       " 'birth': 647,\n",
       " 'waiting': 648,\n",
       " 'moment': 649,\n",
       " 'buy': 650,\n",
       " 'different': 651,\n",
       " 'kind': 652,\n",
       " 'problem': 653,\n",
       " 'special': 654,\n",
       " 'muslim': 655,\n",
       " 'nothing': 656,\n",
       " 'dinner': 657,\n",
       " 'chinese': 658,\n",
       " 'girls': 659,\n",
       " '40': 660,\n",
       " 'sports': 661,\n",
       " 'weekend': 662,\n",
       " 'ice': 663,\n",
       " 'least': 664,\n",
       " 'hit': 665,\n",
       " 'kid': 666,\n",
       " 'congressman': 667,\n",
       " 'k': 668,\n",
       " 'leave': 669,\n",
       " 'following': 670,\n",
       " 'become': 671,\n",
       " 'reasons': 672,\n",
       " 'trailer': 673,\n",
       " 'bring': 674,\n",
       " 'celebrates': 675,\n",
       " 'lessons': 676,\n",
       " 'box': 677,\n",
       " 'conversation': 678,\n",
       " 'vows': 679,\n",
       " 'hope': 680,\n",
       " 'point': 681,\n",
       " 'early': 682,\n",
       " 'cops': 683,\n",
       " 'global': 684,\n",
       " 'powerful': 685,\n",
       " 'host': 686,\n",
       " 'learned': 687,\n",
       " 'driving': 688,\n",
       " 'store': 689,\n",
       " 'taylor': 690,\n",
       " 'syria': 691,\n",
       " 'fox': 692,\n",
       " 'offers': 693,\n",
       " 'returns': 694,\n",
       " 'play': 695,\n",
       " 'turn': 696,\n",
       " 'joe': 697,\n",
       " 'trip': 698,\n",
       " 'rise': 699,\n",
       " 'huge': 700,\n",
       " 'majority': 701,\n",
       " 'adorable': 702,\n",
       " 'whole': 703,\n",
       " 'signs': 704,\n",
       " 'ask': 705,\n",
       " 'senator': 706,\n",
       " 'francis': 707,\n",
       " '100': 708,\n",
       " 'risk': 709,\n",
       " 'cop': 710,\n",
       " 'advice': 711,\n",
       " 'leader': 712,\n",
       " 'millions': 713,\n",
       " 'syrian': 714,\n",
       " 'hits': 715,\n",
       " 'low': 716,\n",
       " \"america's\": 717,\n",
       " 'scott': 718,\n",
       " 'told': 719,\n",
       " 'break': 720,\n",
       " 'program': 721,\n",
       " 'fall': 722,\n",
       " 'gift': 723,\n",
       " 'oil': 724,\n",
       " 'schools': 725,\n",
       " 'victims': 726,\n",
       " 'massive': 727,\n",
       " 'far': 728,\n",
       " 'fashion': 729,\n",
       " 'jimmy': 730,\n",
       " 'turns': 731,\n",
       " 'accused': 732,\n",
       " 'pence': 733,\n",
       " 'stage': 734,\n",
       " 'words': 735,\n",
       " 'kills': 736,\n",
       " 'crash': 737,\n",
       " 'workers': 738,\n",
       " 'tom': 739,\n",
       " 'russian': 740,\n",
       " 'feels': 741,\n",
       " 'date': 742,\n",
       " 'jr': 743,\n",
       " 'song': 744,\n",
       " 'queer': 745,\n",
       " 'band': 746,\n",
       " 'drunk': 747,\n",
       " 'anything': 748,\n",
       " 'puts': 749,\n",
       " 'hands': 750,\n",
       " 'discover': 751,\n",
       " 'j': 752,\n",
       " \"there's\": 753,\n",
       " 'c': 754,\n",
       " 'china': 755,\n",
       " 'oscar': 756,\n",
       " 'reality': 757,\n",
       " 'brings': 758,\n",
       " 'mental': 759,\n",
       " 'breaks': 760,\n",
       " 'defense': 761,\n",
       " 'dance': 762,\n",
       " 'politics': 763,\n",
       " 'fun': 764,\n",
       " 'almost': 765,\n",
       " 'iowa': 766,\n",
       " 'industry': 767,\n",
       " '2017': 768,\n",
       " 'side': 769,\n",
       " '13': 770,\n",
       " 'opens': 771,\n",
       " 'planned': 772,\n",
       " 'decision': 773,\n",
       " 'possible': 774,\n",
       " 'eat': 775,\n",
       " \"they're\": 776,\n",
       " 'playing': 777,\n",
       " 'seen': 778,\n",
       " 'paris': 779,\n",
       " 'starting': 780,\n",
       " 'door': 781,\n",
       " 'experience': 782,\n",
       " 'close': 783,\n",
       " 'candidates': 784,\n",
       " 'hoping': 785,\n",
       " 'bus': 786,\n",
       " 'hate': 787,\n",
       " 'number': 788,\n",
       " 'sick': 789,\n",
       " 'sign': 790,\n",
       " 'anniversary': 791,\n",
       " 'near': 792,\n",
       " 'worried': 793,\n",
       " 'executive': 794,\n",
       " 'huffpost': 795,\n",
       " 'major': 796,\n",
       " 'completely': 797,\n",
       " 'un': 798,\n",
       " 'apple': 799,\n",
       " 'stand': 800,\n",
       " 'university': 801,\n",
       " 'spends': 802,\n",
       " 'killing': 803,\n",
       " 'style': 804,\n",
       " 'chance': 805,\n",
       " 'rubio': 806,\n",
       " 'policy': 807,\n",
       " 'important': 808,\n",
       " '2014': 809,\n",
       " 'chicken': 810,\n",
       " 'worth': 811,\n",
       " 'hand': 812,\n",
       " 'role': 813,\n",
       " 'longer': 814,\n",
       " 'd': 815,\n",
       " 'worst': 816,\n",
       " 'weight': 817,\n",
       " 'green': 818,\n",
       " 'reveal': 819,\n",
       " 'halloween': 820,\n",
       " 'whether': 821,\n",
       " 'moore': 822,\n",
       " 'light': 823,\n",
       " 'moving': 824,\n",
       " 'fear': 825,\n",
       " 'true': 826,\n",
       " 'members': 827,\n",
       " 'trans': 828,\n",
       " 'google': 829,\n",
       " 'check': 830,\n",
       " 'wishes': 831,\n",
       " 'cut': 832,\n",
       " 'billion': 833,\n",
       " 'reform': 834,\n",
       " 'lgbt': 835,\n",
       " 'weird': 836,\n",
       " 'system': 837,\n",
       " 'album': 838,\n",
       " 'moms': 839,\n",
       " 'prince': 840,\n",
       " 'across': 841,\n",
       " 'mass': 842,\n",
       " 'key': 843,\n",
       " 'williams': 844,\n",
       " 'results': 845,\n",
       " 'board': 846,\n",
       " 'adds': 847,\n",
       " 'success': 848,\n",
       " 'building': 849,\n",
       " 'general': 850,\n",
       " 'employees': 851,\n",
       " 'reportedly': 852,\n",
       " 'data': 853,\n",
       " 'epa': 854,\n",
       " 'went': 855,\n",
       " 'voter': 856,\n",
       " 'allegations': 857,\n",
       " 'center': 858,\n",
       " 'hilarious': 859,\n",
       " 'voice': 860,\n",
       " 'culture': 861,\n",
       " 'card': 862,\n",
       " 'simple': 863,\n",
       " 'pick': 864,\n",
       " 'struggling': 865,\n",
       " 'nyc': 866,\n",
       " 'hurricane': 867,\n",
       " 'amazing': 868,\n",
       " 'iraq': 869,\n",
       " 'explains': 870,\n",
       " 'economy': 871,\n",
       " 'throws': 872,\n",
       " 'steve': 873,\n",
       " 'chicago': 874,\n",
       " 'tour': 875,\n",
       " 'worse': 876,\n",
       " 'bowl': 877,\n",
       " 'given': 878,\n",
       " 'carolina': 879,\n",
       " 'governor': 880,\n",
       " 'try': 881,\n",
       " 'wait': 882,\n",
       " 'happened': 883,\n",
       " 'opening': 884,\n",
       " 'final': 885,\n",
       " \"let's\": 886,\n",
       " 'nfl': 887,\n",
       " 'mind': 888,\n",
       " 'west': 889,\n",
       " 'begins': 890,\n",
       " 'amazon': 891,\n",
       " 'desperate': 892,\n",
       " 'vacation': 893,\n",
       " 'sales': 894,\n",
       " 'audience': 895,\n",
       " 'suicide': 896,\n",
       " 'leads': 897,\n",
       " 'keeps': 898,\n",
       " 'murder': 899,\n",
       " 'colbert': 900,\n",
       " 'artist': 901,\n",
       " 'shares': 902,\n",
       " 'performance': 903,\n",
       " 'coffee': 904,\n",
       " 'pro': 905,\n",
       " 'easy': 906,\n",
       " 'remember': 907,\n",
       " 'magazine': 908,\n",
       " 'sean': 909,\n",
       " 'documentary': 910,\n",
       " 'official': 911,\n",
       " 'hopes': 912,\n",
       " 'dating': 913,\n",
       " 'abuse': 914,\n",
       " 'football': 915,\n",
       " 'uses': 916,\n",
       " 'train': 917,\n",
       " 'lead': 918,\n",
       " 'holding': 919,\n",
       " 'test': 920,\n",
       " 'problems': 921,\n",
       " 'plane': 922,\n",
       " 'netflix': 923,\n",
       " 'energy': 924,\n",
       " 'officer': 925,\n",
       " 'ben': 926,\n",
       " 'act': 927,\n",
       " 'table': 928,\n",
       " 'names': 929,\n",
       " 'israel': 930,\n",
       " 'proud': 931,\n",
       " 'michelle': 932,\n",
       " 'homeless': 933,\n",
       " 'press': 934,\n",
       " 'poor': 935,\n",
       " 'robert': 936,\n",
       " 'apartment': 937,\n",
       " 'jobs': 938,\n",
       " '18': 939,\n",
       " 'church': 940,\n",
       " 'kerry': 941,\n",
       " 'pregnant': 942,\n",
       " 'transgender': 943,\n",
       " 'planet': 944,\n",
       " 'eye': 945,\n",
       " 'question': 946,\n",
       " 'ferguson': 947,\n",
       " 'voting': 948,\n",
       " 'walking': 949,\n",
       " 'male': 950,\n",
       " 'park': 951,\n",
       " 'leaving': 952,\n",
       " 'oscars': 953,\n",
       " 'families': 954,\n",
       " 'pizza': 955,\n",
       " 'lose': 956,\n",
       " 'amid': 957,\n",
       " 'suspect': 958,\n",
       " 'demand': 959,\n",
       " 'labor': 960,\n",
       " 'protesters': 961,\n",
       " 'road': 962,\n",
       " 'steps': 963,\n",
       " 'dying': 964,\n",
       " 'push': 965,\n",
       " 'supporters': 966,\n",
       " 'suggests': 967,\n",
       " 'force': 968,\n",
       " \"we're\": 969,\n",
       " 'spring': 970,\n",
       " 'boys': 971,\n",
       " 'hall': 972,\n",
       " 'which': 973,\n",
       " 'commercial': 974,\n",
       " 'prevent': 975,\n",
       " 'bob': 976,\n",
       " \"hasn't\": 977,\n",
       " 'deadly': 978,\n",
       " 'surprise': 979,\n",
       " 'co': 980,\n",
       " 'asking': 981,\n",
       " 'incredible': 982,\n",
       " 'youth': 983,\n",
       " 'also': 984,\n",
       " 'arrested': 985,\n",
       " 'perfectly': 986,\n",
       " 'responds': 987,\n",
       " 'lgbtq': 988,\n",
       " 'hear': 989,\n",
       " 'return': 990,\n",
       " 'peace': 991,\n",
       " 'demands': 992,\n",
       " 'science': 993,\n",
       " 'finding': 994,\n",
       " 'clearly': 995,\n",
       " 'picture': 996,\n",
       " 'learn': 997,\n",
       " 'faces': 998,\n",
       " 'christian': 999,\n",
       " 'ebola': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vocabulary\n",
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "neither-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = t.texts_to_sequences(X_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "perceived-cycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[640, 3993, 2, 3994, 68, 7233, 521, 4452, 76, 18, 1]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "collect-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "northern-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define maximum number of words to consider in each headline\n",
    "max_headline_length = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "accepted-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad training and test reviews\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        maxlen=max_headline_length,\n",
    "                                                        padding='pre', truncating='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, \n",
    "                                                       maxlen=max_headline_length, \n",
    "                                                       padding='pre', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "irish-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21367, 300), (5342, 300))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "practical-problem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,  640, 3993,    2, 3994,   68, 7233,  521, 4452,\n",
       "         76,   18,    1])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "gothic-diabetes",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "enabling-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_input_file = 'glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "creative-blues",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Name for word2vec file\n",
    "word2vec_output_file = 'glove.6B.50d.txt.word2vec'\n",
    "#Convert Glove embeddings to Word2Vec embeddings\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-tennessee",
   "metadata": {},
   "source": [
    "7. Vocab size is equal to 400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "closing-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "hungry-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained Glove model (in word2vec form)\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "#Embedding length based on selected model - we are using 50d here.\n",
    "embedding_vector_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-omaha",
   "metadata": {},
   "source": [
    "## 8. Create a weight matrix using GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "electoral-willow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 50)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize embedding matrix\n",
    "embedding_matrix = np.zeros((desired_vocab_size + 1, embedding_vector_length))\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "corrected-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
    "    if i > (desired_vocab_size+1):\n",
    "        break\n",
    "    try:\n",
    "        embedding_vector = glove_model[word] #Reading word's embedding from Glove model for a given word\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "alone-delicious",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68046999, -0.039263  ,  0.30186   , -0.17792   ,  0.42962   ,\n",
       "        0.032246  , -0.41376001,  0.13228001, -0.29846999, -0.085253  ,\n",
       "        0.17117999,  0.22419   , -0.10046   , -0.43652999,  0.33418   ,\n",
       "        0.67846   ,  0.057204  , -0.34448001, -0.42785001, -0.43274999,\n",
       "        0.55962998,  0.10032   ,  0.18677001, -0.26853999,  0.037334  ,\n",
       "       -2.09319997,  0.22171   , -0.39868   ,  0.20912001, -0.55725002,\n",
       "        3.88260007,  0.47466001, -0.95657998, -0.37788001,  0.20869   ,\n",
       "       -0.32752001,  0.12751   ,  0.088359  ,  0.16350999, -0.21634001,\n",
       "       -0.094375  ,  0.018324  ,  0.21048   , -0.03088   , -0.19722   ,\n",
       "        0.082279  , -0.09434   , -0.073297  , -0.064699  , -0.26043999])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word the - index 1\n",
    "embedding_matrix[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-project",
   "metadata": {},
   "source": [
    "## 9. Define and compile a Bidirectional LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "supposed-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "tf.keras.backend.clear_session()\n",
    "model_bd = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "proper-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bd.add(tf.keras.layers.Embedding(desired_vocab_size + 1, #Vocablury size\n",
    "                                    embedding_vector_length, #Embedding size\n",
    "                                    weights=[embedding_matrix], #Embeddings taken from pre-trained model\n",
    "                                    trainable=False, #As embeddings are already available, we will not train this layer. It will act as lookup layer.\n",
    "                                    input_length=max_headline_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "supposed-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bd.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "# model.add(Dense(128, activation=\"relu\"))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(64, activation=\"relu\"))\n",
    "# model.add(Dropout(0.4))\n",
    "model_bd.add(Dense(64, activation=\"relu\"))\n",
    "model_bd.add(Dropout(0.5))\n",
    "model_bd.add(Dense(16, activation=\"relu\"))\n",
    "model_bd.add(Dropout(0.5))\n",
    "model_bd.add(Dense(1, activation=\"sigmoid\"))\n",
    "model_bd.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "latest-cornwall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/Sigmoid:0' shape=(None, 300, 1) dtype=float32>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bd.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ec947d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 50)           500050    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 300, 256)          183296    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300, 64)           16448     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 64)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300, 16)           1040      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300, 1)            17        \n",
      "=================================================================\n",
      "Total params: 700,851\n",
      "Trainable params: 200,801\n",
      "Non-trainable params: 500,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd4d3f",
   "metadata": {},
   "source": [
    "## 10. Fit the model and check the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2d388fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "668/668 [==============================] - 181s 271ms/step - loss: 0.6711 - accuracy: 0.5815 - val_loss: 0.6764 - val_accuracy: 0.5719\n",
      "Epoch 2/10\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 0.6668 - accuracy: 0.6008 - val_loss: 0.6607 - val_accuracy: 0.6102\n",
      "Epoch 3/10\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 0.6700 - accuracy: 0.5848 - val_loss: 0.6765 - val_accuracy: 0.5694\n",
      "Epoch 4/10\n",
      "668/668 [==============================] - 195s 292ms/step - loss: 0.6763 - accuracy: 0.5694 - val_loss: 0.6766 - val_accuracy: 0.5696\n",
      "Epoch 5/10\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 0.6757 - accuracy: 0.5710 - val_loss: 0.6772 - val_accuracy: 0.5697\n",
      "Epoch 6/10\n",
      "668/668 [==============================] - 196s 293ms/step - loss: 0.6747 - accuracy: 0.5711 - val_loss: 0.6757 - val_accuracy: 0.5707\n",
      "Epoch 7/10\n",
      "668/668 [==============================] - 196s 294ms/step - loss: 0.6701 - accuracy: 0.5727 - val_loss: 0.6583 - val_accuracy: 0.5725\n",
      "Epoch 8/10\n",
      "668/668 [==============================] - 208s 311ms/step - loss: 0.6381 - accuracy: 0.6081 - val_loss: 0.6445 - val_accuracy: 0.6429\n",
      "Epoch 9/10\n",
      "668/668 [==============================] - 205s 306ms/step - loss: 0.5342 - accuracy: 0.7563 - val_loss: 0.4875 - val_accuracy: 0.7562\n",
      "Epoch 10/10\n",
      "668/668 [==============================] - 203s 304ms/step - loss: 0.4613 - accuracy: 0.7990 - val_loss: 0.4433 - val_accuracy: 0.7771\n"
     ]
    }
   ],
   "source": [
    "results = model_bd.fit(X_train, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,          \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "committed-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 151s 226ms/step - loss: 0.3979 - accuracy: 0.8056\n",
      "Training loss is: 0.39787793159484863\n",
      "Training accuracy is: 0.8055902719497681\n",
      "167/167 [==============================] - 37s 220ms/step - loss: 0.4433 - accuracy: 0.7771\n",
      "Test loss is: 0.44334205985069275\n",
      "Test accuracy is: 0.7771157622337341\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "score, acc = model_bd.evaluate(X_train, y_train, batch_size=32)\n",
    "print(\"Training loss is:\", score)\n",
    "print('Training accuracy is:', acc)\n",
    "\n",
    "# Testing data\n",
    "score, acc = model_bd.evaluate(X_test, y_test, batch_size=32)\n",
    "print(\"Test loss is:\", score)\n",
    "print('Test accuracy is:', acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Project_Sarcasm_Detection_Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
